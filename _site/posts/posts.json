[
  {
    "path": "posts/2021-08-30-hands-on-exercise-2/",
    "title": "Hands-On Exercise 2",
    "description": "Today's Adventure: Geospatial Data Wrangling with R! Using the sf package, let's learn the ropes of handling geospatial data in R: from importing to projection, we've got you covered ðŸ’ª You might even learn a geoprocessing tip or two ðŸ˜„",
    "author": [
      {
        "name": "Megan Sim",
        "url": "https://www.linkedin.com/in/megan-sim-tze-yen/"
      }
    ],
    "date": "2021-08-30",
    "categories": [
      "Hands-On Exercise",
      "R",
      "sf",
      "ggplot2"
    ],
    "contents": "\r\n\r\nContents\r\n1.0 Overview\r\n2.0 Setup\r\n2.1 Packages Used\r\n2.2 Data Used\r\n\r\n3.0 Importing Geospatial Data into R\r\n3.1 Importing polygon feature data in shapefile format\r\n3.2 Importing polyline feature data in shapefile form\r\n3.3 Importing GIS data in kml format\r\n\r\n4.0 Importing + Converting Aspatial Data into R\r\n4.1 Importing aspatial data\r\n4.2 Converting aspatial data\r\n4.3 Combining it together: Importing asptial data as sf\r\n\r\n5.0 Checking the Content of a Data Frame\r\n5.1 st_geometry()\r\n5.2 glimpse()\r\n5.3 head()\r\n\r\n6.0 Plotting & Projection\r\n6.1 Plotting\r\n6.2 Projection\r\n\r\n7.0 Geoprocessing\r\n7.1 Buffering\r\n7.2 Point-In-Polygon Count\r\n\r\n8.0 Exploratory Data Analysis (EDA)\r\nDIY section\r\n\r\n7.0 End Notes\r\n\r\n1.0 Overview\r\nBefore we even start, you might be wondering: why geospatial analytics? Why are we learning about it, and how is it relevant to a business or a governmental/academic institution?\r\nA quick Google search brings up thousands upon thousands of answers, articles, and research papers: I recommend Deloitteâ€™s 3-Minute Guide on why geospatial analytics matters and the value it brings to a business its data.\r\n\r\n\r\nIn todayâ€™s Hands-On Exercise, weâ€™ll be doing an introduction to geospatial analytics in R:\r\nimporting the data and (if necessary) converting it into an accessible format\r\ncarrying out geoprocessing tasks with sf\r\ncarrying out data wrangling tasks with dplyr\r\nperforming Exploratory Data Analysis (EDA) with ggplot2\r\n2.0 Setup\r\n2.1 Packages Used\r\n\r\n\r\nThe R packages weâ€™ll be introducing today are: - sf: used for importing, managing, and processing geospatial data - tidyverse: used for importing, wrangling and visualising data (and other data science tasks!)\r\n\r\nNote: Tidyverse consists of a family of R packages, such as readr, tidyr, and dplyr - these are used for the different steps of the data wrangling + visualisation process!\r\n\r\nHereâ€™s a handy code chunk that weâ€™ll likely be putting at the start of every file: it (a) creates a list of packages, (b) checks if they have been installed (and installs it for us if they havenâ€™t), and lastly (c) launches them in the Rstudio environment.\r\n\r\n\r\npackages = c('sf', 'tidyverse')\r\nfor (p in packages){\r\n  if(!require(p, character.only = T)){\r\n    install.packages(p)\r\n  }\r\n  library(p,character.only = T)\r\n}\r\n\r\n\r\n\r\n2.2 Data Used\r\nThe datasets used for this exercise are:\r\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\r\nPre-Schools Location from data.gov.sg\r\nCycling Path from LTADataMall\r\nSingapore Airbnb listing data, 19 July 2021 from Inside Airbnb\r\nA good practice would be to put the data sets in a â€˜dataâ€™ folder, sorted accordingly into â€˜geospatialâ€™ and â€˜aspatialâ€™ folders.\r\n\r\n\r\n3.0 Importing Geospatial Data into R\r\nNow that weâ€™ve got our data, letâ€™s take a closer look at the formats theyâ€™re in and how to import them into R. The geospatial data we have are:\r\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\r\nCyclingPath, a line feature layer in ESRI shapefile format, and\r\nPreSchool, a point feature layer in kml file format.\r\nTo import, weâ€™ll be using a handy function called st_read() from the sf package. The arguments it takes in depends on the file format. For the shapefile format, two arguments are provided: dsn to define the data path, and layer to provide the shapefile name. Bonus: we donâ€™t need to specify the file extension for shapefiles ðŸ˜„ On the other hand, for the kml file format, our argument is the complete path with the kml file extension.\r\n\r\n\r\n3.1 Importing polygon feature data in shapefile format\r\nDataset used: MP14_SUBZONE_WEB_PL File format: shapefile Data frame type: polygon feature\r\n\r\n\r\nmpsz = st_read(dsn = \"data/geospatial\", \r\n                  layer = \"MP14_SUBZONE_WEB_PL\")\r\n\r\n\r\nReading layer `MP14_SUBZONE_WEB_PL' from data source \r\n  `C:\\Users\\megan\\relevant\\University Materials\\IS415 Geospatial Analytics & Applications\\RStudio\\IS415_msty\\_posts\\2021-08-30-hands-on-exercise-2\\data\\geospatial' \r\n  using driver `ESRI Shapefile'\r\nSimple feature collection with 323 features and 15 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\r\nProjected CRS: SVY21\r\n\r\nFrom the output message, we can see that in our mpsz simple feature data frame, there are 323 multipolygon features, 15 fields and is in the svy21 projected coordinates system.\r\n3.2 Importing polyline feature data in shapefile form\r\nDataset used: CyclingPath File format: shapefile Data frame type: line feature\r\n\r\n\r\ncyclingpath = st_read(dsn = \"data/geospatial\", \r\n                         layer = \"CyclingPath\")\r\n\r\n\r\nReading layer `CyclingPath' from data source \r\n  `C:\\Users\\megan\\relevant\\University Materials\\IS415 Geospatial Analytics & Applications\\RStudio\\IS415_msty\\_posts\\2021-08-30-hands-on-exercise-2\\data\\geospatial' \r\n  using driver `ESRI Shapefile'\r\nSimple feature collection with 3336 features and 2 fields\r\nGeometry type: MULTILINESTRING\r\nDimension:     XY\r\nBounding box:  xmin: 12831.45 ymin: 28347.98 xmax: 42799.89 ymax: 48948.15\r\nProjected CRS: SVY21\r\n\r\nFrom the output message, we can see that in our cyclingpath linestring feature data frame, there are 1625 linestring features, 2 fields and is in the svy21 projected coordinates system.\r\n3.3 Importing GIS data in kml format\r\nDataset used: pre-schools-location-kml File format: kml Data frame type: point feature\r\n\r\n\r\npreschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\r\n\r\n\r\nReading layer `PRESCHOOLS_LOCATION' from data source \r\n  `C:\\Users\\megan\\relevant\\University Materials\\IS415 Geospatial Analytics & Applications\\RStudio\\IS415_msty\\_posts\\2021-08-30-hands-on-exercise-2\\data\\geospatial\\pre-schools-location-kml.kml' \r\n  using driver `KML'\r\nSimple feature collection with 1925 features and 2 fields\r\nGeometry type: POINT\r\nDimension:     XYZ\r\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\r\nz_range:       zmin: 0 zmax: 0\r\nGeodetic CRS:  WGS 84\r\n\r\nFrom the output message, we can see that in our preschool point feature data frame, there are 1359 linestring features, 2 fields and is in the wgs84 projected coordinates system.\r\n4.0 Importing + Converting Aspatial Data into R\r\nFor aspatial data, such as the listings Airbnb datset, thereâ€™s an extra step in the importing process. Weâ€™ll import it into a tibble data frame, then convert it into a simple feature data frame.\r\n4.1 Importing aspatial data\r\nSince our listings data set is in a csv file format, weâ€™ll use the read_csv() function from the readr package, like so:\r\n\r\n\r\nlistings <- read_csv(\"data/aspatial/listings.csv\")\r\nglimpse(listings) \r\n\r\n\r\nRows: 4,252\r\nColumns: 16\r\n$ id                             <dbl> 50646, 71609, 71896, 71903, 2~\r\n$ name                           <chr> \"Pleasant Room along Bukit Ti~\r\n$ host_id                        <dbl> 227796, 367042, 367042, 36704~\r\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belind~\r\n$ neighbourhood_group            <chr> \"Central Region\", \"East Regio~\r\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"T~\r\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.~\r\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596,~\r\n$ room_type                      <chr> \"Private room\", \"Private room~\r\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, ~\r\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8~\r\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, ~\r\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014~\r\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20,~\r\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50,~\r\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364,~\r\n\r\nFrom the output message, we can see that in our listing tibble data frame, there are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!) Take note of the latitude and longitude fields - weâ€™ll be using them in the next phase.\r\n\r\nAssumption: The data is in the wgs84 Geographic Coordinate System on account of its latitude/longtitude fields.\r\n\r\n4.2 Converting aspatial data\r\nNow, letâ€™s convert our listing tibble data frame into a by using the st_as_sf() function from the sf package.\r\n\r\n\r\nlistings_sf <- st_as_sf(listings, \r\n                       coords = c(\"longitude\", \"latitude\"),\r\n                       crs=4326) %>%\r\n  st_transform(crs = 3414)\r\n\r\n\r\n\r\nLetâ€™s explain the code chunk!\r\n\r\n\r\nThis gives us the new simple feature data frame, listings_sf:\r\n\r\n\r\nglimpse(listings_sf)\r\n\r\n\r\nRows: 4,252\r\nColumns: 15\r\n$ id                             <dbl> 50646, 71609, 71896, 71903, 2~\r\n$ name                           <chr> \"Pleasant Room along Bukit Ti~\r\n$ host_id                        <dbl> 227796, 367042, 367042, 36704~\r\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belind~\r\n$ neighbourhood_group            <chr> \"Central Region\", \"East Regio~\r\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"T~\r\n$ room_type                      <chr> \"Private room\", \"Private room~\r\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, ~\r\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8~\r\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, ~\r\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014~\r\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20,~\r\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50,~\r\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364,~\r\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9~\r\n\r\n\r\nNote that a new column called geometry has been added! In addition, longtitude and latitude have both been dropped.\r\n\r\n4.3 Combining it together: Importing asptial data as sf\r\n5.0 Checking the Content of a Data Frame\r\nNow that weâ€™ve got our data frames, this begs the question: what exactly is inside them? Letâ€™s learn how to retrieve the information of the dataframe with 3 simple methods!\r\n5.1 st_geometry()\r\nLetâ€™s say that we want a preliminary look at our data - just seeing the basic feature information is sufficient. In this case, st_geometry() is most appropriate:\r\n\r\n\r\nst_geometry(mpsz)\r\n\r\n\r\nGeometry set for 323 features \r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\r\nProjected CRS: SVY21\r\nFirst 5 geometries:\r\n\r\nAs we can see, only the basic information of the feature class (type of geometry, geographic extent of features and CRS) is displayed.\r\n5.2 glimpse()\r\nHowever, basic information wonâ€™t take us very far. Letâ€™s dig a little deeper and learn about the associated attribute information in the data frame. This is where glimpse() comes in:\r\n\r\n\r\nglimpse(mpsz)\r\n\r\n\r\nRows: 323\r\nColumns: 16\r\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15~\r\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1,~\r\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HEN~\r\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\",~\r\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\",~\r\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUK~\r\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"~\r\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGI~\r\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"~\r\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF0~\r\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, ~\r\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96,~\r\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70,~\r\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594,~\r\n$ SHAPE_Area <dbl> 1630379.3, 559816.2, 160807.5, 595428.9, 387429.4~\r\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULT~\r\n\r\nWith glimpse(), we now know the data type of each field - for example, FMEL-UPD_D field is of the date data type.\r\n5.3 head()\r\nSometimes, we want to dig as deep as we can and reveal all the information of a feature object. In this case, head() is best:\r\n\r\n\r\nhead(mpsz)\r\n\r\n\r\nSimple feature collection with 6 features and 15 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: 24468.89 ymin: 28369.47 xmax: 32362.39 ymax: 30542.74\r\nProjected CRS: SVY21\r\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\r\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\r\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\r\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\r\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\r\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\r\n6        6          7 ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\r\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D\r\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05\r\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05\r\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05\r\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05\r\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05\r\n6         BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05\r\n    X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area\r\n1 31595.84 29220.19   5267.381  1630379.3\r\n2 28679.06 29782.05   3506.107   559816.2\r\n3 29654.96 29974.66   1740.926   160807.5\r\n4 26782.83 29933.77   3313.625   595428.9\r\n5 26201.96 30005.70   2825.594   387429.4\r\n6 25358.82 29991.38   4428.913  1030378.8\r\n                        geometry\r\n1 MULTIPOLYGON (((31495.56 30...\r\n2 MULTIPOLYGON (((29092.28 30...\r\n3 MULTIPOLYGON (((29932.33 29...\r\n4 MULTIPOLYGON (((27131.28 30...\r\n5 MULTIPOLYGON (((26451.03 30...\r\n6 MULTIPOLYGON (((25899.7 297...\r\n\r\n\r\nNote that the â€˜nâ€™ argument allows us to select how many records to display!\r\n\r\n6.0 Plotting & Projection\r\n6.1 Plotting\r\nNow that weâ€™ve got our data, we get into the meat of the matter: visualisation! Having a dataframe of fields and data points is taxing for human eyes to process, but with a bit of plotting and mapping, our geospatial data becomes a gold mine of great insights. Letâ€™s try to plot() it out:\r\n\r\n\r\nplot(mpsz)\r\n\r\n\r\n\r\n\r\nThis is a handy multi-plot of all attributes (up to a reasonable amount). But maybe we just want to plot a specific attribute:\r\n\r\n\r\nplot(mpsz[\"PLN_AREA_N\"])\r\n\r\n\r\n\r\n\r\nThere are also times where we need just the geometry - in other words, the map outline:\r\n\r\n\r\nplot(st_geometry(mpsz))\r\n\r\n\r\n\r\n\r\n6.2 Projection\r\nProjection transformation is when we project a simple feature data frame from one coordinate system to another. There are two common issues that require projection transformation: (a) missing or inaccurate coordinate system, or (b) inappropriate coordinate systems for the analysis chosen.\r\n6.2.1 Missing/Inaccurate Coordinate System\r\nTo tackle the first issue, weâ€™ll need to assign an ESPG code to the data frame. Firstly, letâ€™s check the coordinate system of our mpsz data frame:\r\n\r\n\r\nst_crs(mpsz)\r\n\r\n\r\nCoordinate Reference System:\r\n  User input: SVY21 \r\n  wkt:\r\nPROJCRS[\"SVY21\",\r\n    BASEGEOGCRS[\"SVY21[WGS84]\",\r\n        DATUM[\"World Geodetic System 1984\",\r\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\r\n                LENGTHUNIT[\"metre\",1]],\r\n            ID[\"EPSG\",6326]],\r\n        PRIMEM[\"Greenwich\",0,\r\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\r\n    CONVERSION[\"unnamed\",\r\n        METHOD[\"Transverse Mercator\",\r\n            ID[\"EPSG\",9807]],\r\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\r\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\r\n            ID[\"EPSG\",8801]],\r\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\r\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\r\n            ID[\"EPSG\",8802]],\r\n        PARAMETER[\"Scale factor at natural origin\",1,\r\n            SCALEUNIT[\"unity\",1],\r\n            ID[\"EPSG\",8805]],\r\n        PARAMETER[\"False easting\",28001.642,\r\n            LENGTHUNIT[\"metre\",1],\r\n            ID[\"EPSG\",8806]],\r\n        PARAMETER[\"False northing\",38744.572,\r\n            LENGTHUNIT[\"metre\",1],\r\n            ID[\"EPSG\",8807]]],\r\n    CS[Cartesian,2],\r\n        AXIS[\"(E)\",east,\r\n            ORDER[1],\r\n            LENGTHUNIT[\"metre\",1,\r\n                ID[\"EPSG\",9001]]],\r\n        AXIS[\"(N)\",north,\r\n            ORDER[2],\r\n            LENGTHUNIT[\"metre\",1,\r\n                ID[\"EPSG\",9001]]]]\r\n\r\nAlthough mpsz data frame is projected in svy21, the output indicates that the EPSG is 9001. This is the wrong EPSG code! The correct EPSG code for svy21 should be 3414. Letâ€™s change it:\r\n\r\n\r\nmpsz3414 <- st_set_crs(mpsz, 3414)\r\nst_crs(mpsz3414)\r\n\r\n\r\nCoordinate Reference System:\r\n  User input: EPSG:3414 \r\n  wkt:\r\nPROJCRS[\"SVY21 / Singapore TM\",\r\n    BASEGEOGCRS[\"SVY21\",\r\n        DATUM[\"SVY21\",\r\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\r\n                LENGTHUNIT[\"metre\",1]]],\r\n        PRIMEM[\"Greenwich\",0,\r\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\r\n        ID[\"EPSG\",4757]],\r\n    CONVERSION[\"Singapore Transverse Mercator\",\r\n        METHOD[\"Transverse Mercator\",\r\n            ID[\"EPSG\",9807]],\r\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\r\n            ANGLEUNIT[\"degree\",0.0174532925199433],\r\n            ID[\"EPSG\",8801]],\r\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\r\n            ANGLEUNIT[\"degree\",0.0174532925199433],\r\n            ID[\"EPSG\",8802]],\r\n        PARAMETER[\"Scale factor at natural origin\",1,\r\n            SCALEUNIT[\"unity\",1],\r\n            ID[\"EPSG\",8805]],\r\n        PARAMETER[\"False easting\",28001.642,\r\n            LENGTHUNIT[\"metre\",1],\r\n            ID[\"EPSG\",8806]],\r\n        PARAMETER[\"False northing\",38744.572,\r\n            LENGTHUNIT[\"metre\",1],\r\n            ID[\"EPSG\",8807]]],\r\n    CS[Cartesian,2],\r\n        AXIS[\"northing (N)\",north,\r\n            ORDER[1],\r\n            LENGTHUNIT[\"metre\",1]],\r\n        AXIS[\"easting (E)\",east,\r\n            ORDER[2],\r\n            LENGTHUNIT[\"metre\",1]],\r\n    USAGE[\r\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\r\n        AREA[\"Singapore - onshore and offshore.\"],\r\n        BBOX[1.13,103.59,1.47,104.07]],\r\n    ID[\"EPSG\",3414]]\r\n\r\n6.2.2 Inappropriate Coordinate Systems\r\nStill remember our geospatial data overview in 3.0? You might have noticed that the coordinate system differed among our data frames: mpsz and cyclingpath are svy21, while preschool is wgs84. preschool might run into issues when weâ€™re performing geoprocessing, because a geographic coordinate system is not appropriate if our analysis needs distance or/and area measurements.\r\n\r\n\r\npreschool3414 <- st_transform(preschool, \r\n                              crs = 3414)\r\nst_geometry(preschool3414)\r\n\r\n\r\nGeometry set for 1925 features \r\nGeometry type: POINT\r\nDimension:     XYZ\r\nBounding box:  xmin: 11203.01 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\r\nz_range:       zmin: 0 zmax: 0\r\nProjected CRS: SVY21 / Singapore TM\r\nFirst 5 geometries:\r\n\r\nNotice the change to the svy21 projected coordinate system!\r\n\r\nYou might notice that the values in the bounding box have changed, too! They are now greater than the original 0-360 range of decimal degree commonly used by majority of the geographic coordinate systems.\r\n\r\n7.0 Geoprocessing\r\nOther than handling data, the handy sf package also has functions for geoprocessing (otherwise known as GIS analysis). Letâ€™s explore some commonly-used geoprocessingn functions!\r\n7.1 Buffering\r\nLetâ€™s say that in a bid to promote healthier living, the authorities are planning to upgrade the existing cycling paths, making it safer and more appealing to cyclists all around! To do that, theyâ€™ll need to acquire 5 metres of reserved land on both sides of the cycling path. Our task is to find the total area of land thatâ€™s to be acquired.\r\nFirstly, letâ€™s compute the 5-meter buffers around the cycling paths:\r\n\r\n\r\nbuffer_cycling <- st_buffer(cyclingpath, \r\n                               dist=5, nQuadSegs = 30)\r\n\r\n\r\n\r\nThen, letâ€™s actually calculate the area of the buffers:\r\n\r\n\r\nbuffer_cycling$AREA <- st_area(buffer_cycling)\r\n\r\n\r\n\r\nLastly, letâ€™s find the total area with sum():\r\n\r\n\r\nsum(buffer_cycling$AREA)\r\n\r\n\r\n1642750 [m^2]\r\n\r\n7.2 Point-In-Polygon Count\r\nLetâ€™s say that a preschool service group is organising a nation-wide event, and wants to find out the number of preschools in each Planning Subzone.\r\nWe can kill two birds with one stone with this handy combination of st_intersects() and length(). st_intersects() helps us identify the preschools located in each Planningn Subzone, while length() calculates the number of preschools per Planning Subzone.\r\n\r\n\r\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))\r\n\r\n\r\n\r\nLetâ€™s check a summary of PreSch Count:\r\n\r\n\r\nsummary(mpsz3414$`PreSch Count`)\r\n\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n   0.00    0.00    3.00    5.96    9.00   58.00 \r\n\r\nNow, the preschool service group wants to hold a subzone-specific event! They want to target the Planning Subzone with the most number of preschools to maximise their outreach, so letâ€™s help them out with top_n():\r\n\r\n\r\ntop_n(mpsz3414, 1, `PreSch Count`)\r\n\r\n\r\nSimple feature collection with 1 feature and 16 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\r\nProjected CRS: SVY21 / Singapore TM\r\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N\r\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES\r\n  PLN_AREA_C    REGION_N REGION_C          INC_CRC FMEL_UPD_D\r\n1         TM EAST REGION       ER 21658EAAF84F4D8D 2014-12-05\r\n    X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area\r\n1 41122.55 37392.39   10180.62    4339824\r\n                        geometry PreSch Count\r\n1 MULTIPOLYGON (((42196.76 38...           58\r\n\r\nLastly, the preschool service group wants to know the density of preschools by planning subzone for future events. Weâ€™ll need to derive the area of each planning subzone:\r\n\r\n\r\nmpsz3414$Area <- mpsz3414 %>%\r\n  st_area()\r\n\r\n\r\n\r\nNow, introducing a new function, mutate()! Itâ€™s to help us add the density column into mpsz3414:\r\n\r\n\r\nmpsz3414 <- mpsz3414 %>%\r\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\r\n\r\n\r\n\r\n\r\nWhile they look similar and have a similar function (to add new variables), thereâ€™s a difference between mutate() and transmute()! mutate() adds new variables and preserves existing ones while transmute() adds new variables and drops existing ones. Use the appropriate one for the situation!\r\n\r\n8.0 Exploratory Data Analysis (EDA)\r\nWhy do we do EDA? Hereâ€™s a great Medium article that introduces EDA: from its significance to its components, itâ€™s got you covered!\r\n\r\n\r\nFor this EDA section, weâ€™ll be introducing various ggplot2 functions thatâ€™ll help us create functional and yet truthful statistical graphs thatâ€™ll help us visualise and understand our data!\r\nFirstly, letâ€™s use hist() to plot a histogram and reveal the distribution of PreSch Density:\r\n\r\n\r\nhist(mpsz3414$`PreSch Density`)\r\n\r\n\r\n\r\n\r\nThat looks good - but itâ€™s not something youâ€™ll publish in your reports! Letâ€™s add a little customisation:\r\n\r\n\r\nggplot(data=mpsz3414, \r\n       aes(x= as.numeric(`PreSch Density`)))+\r\n  geom_histogram(bins=20, \r\n                 color=\"black\", \r\n                 fill=\"light blue\") +\r\n  labs(title = \"Are pre-school even distributed in Singapore?\",\r\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\r\n      x = \"Pre-school density (per km sq)\",\r\n      y = \"Frequency\")\r\n\r\n\r\n\r\n\r\nDIY section\r\nDIY: Using ggplot2, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\r\nLetâ€™s approach this step-by-step. Firstly, weâ€™ll need the variables Pre-school Density and Pre-school Count. Luckily, weâ€™ve already created both in 2.5.2 Point-In-Polygon Count.\r\nNext, we need to plot a scatterplot. For our histogram, we used geom_histogram - and for a scatterplot, weâ€™ll use geom_point. We can further customise this by adjusting the colour, size and fill of the points, like so:\r\n\r\n\r\nggplot(data=mpsz3414, \r\n       aes(y = `PreSch Count`, \r\n           x= as.numeric(`PreSch Density`)))+\r\n  geom_point(color=\"black\", \r\n             fill=\"light blue\") + \r\n  labs(title = \"\",\r\n      x = \"Pre-school density (per km sq)\",\r\n      y = \"Pre-school count\")\r\n\r\n\r\n\r\n\r\nSeem finished? Thereâ€™s actually one more step: ensuring that your data is presented as fairly as possible - we donâ€™t want to mislead our readers ðŸ˜± In this case, notice that the aspect ratio of our graph is off - its height is greater than its width! Letâ€™s correct that by setting limiters with the xlim() and ylim() functions inside ggplot2:\r\n\r\n\r\n\r\nAnd there we have it! A representative scatterplot visualisation âœ¨\r\n7.0 End Notes\r\nThis is the end of this weekâ€™s exercise! Iâ€™m really excited to learn more about geospatial analytics: weâ€™ve just begun to scratch the surface, and thereâ€™s so much more to explore and experiment with!\r\nOn a related sidenote: Iâ€™ve learned a number of things myself when creating this blog post! For example, I wanted to have a table of contents, but googling â€˜sidebar navigation paneâ€™ proved to be far less effective than just reading the Distill Basics - which is a lesson learnt on reading the provided materials!\r\nOn a funny note, hereâ€™s a mini-comic on my experience with tabsets:\r\n\r\n\r\nTabsets are meant for html documents, but this output is a distill articleâ€¦ Of course it didnâ€™t work ðŸ˜­ Well, thatâ€™s just another learning point in our Geospatial Analytics Journey !\r\nWalk with me as we dive deeper the coming weeks! ðŸ¤— ðŸ’– âœ¨\r\nP.S. I found my old tablet so I could illustrate the points better! Handwriting will be more consistent from this blog post onwards ðŸ˜„\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-09-02T14:52:34+08:00",
    "input_file": "hands-on-exercise-2.knit.md"
  },
  {
    "path": "posts/2021-08-23-in-class-exercise-2/",
    "title": "In-Class Exercise 2",
    "description": "This is a dummy blog post for testing out the various ins and outs of a Distill blog. In this hands-on exercise, I learned how to handle geospatial data in R by using the sf package.",
    "author": [
      {
        "name": "Megan Sim",
        "url": "https://www.linkedin.com/in/megan-sim-tze-yen/"
      }
    ],
    "date": "2021-08-23",
    "categories": [],
    "contents": "\r\nGetting Started\r\nThis code chunk performs three tasks:\r\nA packaging list call packages will be created. It consists of all the R packages required to accomplish this hands-on exercise.\r\nNext, the code chunk will check if the R packages in packages have been installed in R. If they have yet been installed, they will be installed.\r\nAfter all the R packages have been installed, they will be launched in RStudio environment.\r\n\r\n\r\npackages <- c('sf', 'tidyverse')\r\nfor(p in packages){\r\n  if(!require(p, character.only = T)){\r\n    install.packages(p)\r\n  }\r\n  library(p, character.only = T)\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-08-30T19:56:18+08:00",
    "input_file": {}
  }
]
